import numpy as np

def tanh(x):
    return np.tanh(x)

def tanh_derivative(x):
    return 1.0 - np.tanh(x)**2

class NeuralNetwork:
    def __init__(self, layers):
        self.activation = tanh
        self.activation_derivative = tanh_derivative
        self.weights = []
        self.biases = []
        for i in range(1, len(layers)):
            self.weights.append(np.random.randn(layers[i], layers[i-1]))
            self.biases.append(np.random.randn(layers[i], 1))
    
    def feedforward(self, inputs):
        activations = [inputs]
        for i in range(len(self.weights)):
            activations.append(self.activation(np.dot(self.weights[i], activations[-1]) + self.biases[i]))
        return activations[-1]
    
    def backpropagation(self, inputs, targets, learning_rate):
        activations = [inputs]
        weighted_inputs = []
        for i in range(len(self.weights)):
            weighted_input = np.dot(self.weights[i], activations[-1]) + self.biases[i]
            weighted_inputs.append(weighted_input)
            activations.append(self.activation(weighted_input))
        
        output_errors = targets - activations[-1]
        deltas = [output_errors * self.activation_derivative(weighted_inputs[-1])]
        for i in range(len(self.weights)-1, 0, -1):
            deltas.insert(0, np.dot(self.weights[i].T, deltas[0]) * self.activation_derivative(weighted_inputs[i-1]))
        
        for i in range(len(self.weights)):
            self.weights[i] += learning_rate * np.dot(deltas[i], activations[i].T)
            self.biases[i] += learning_rate * np.sum(deltas[i], axis=1, keepdims=True)
    
    def train(self, inputs, targets, learning_rate, epochs):
        for _ in range(epochs):
            for i in range(len(inputs)):
                self.backpropagation(inputs[i], targets[i], learning_rate)

# Example usage
# Define the neural network architecture: 2 input neurons, 2 hidden neurons, 1 output neuron
# Input layer has 2 neurons, hidden layer has 2 neurons, and output layer has 1 neuron
nn = NeuralNetwork([2, 2, 1])

# Example training data
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
targets = np.array([[0], [1], [1], [0]])

# Train the neural network
nn.train(inputs, targets, learning_rate=0.1, epochs=1000)

# Make predictions
for i in range(len(inputs)):
    prediction = nn.feedforward(inputs[i])
    print(f"Input: {inputs[i]} Predicted Output: {prediction}")
